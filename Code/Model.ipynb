{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours import bm25_weight\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import spotipy\n",
    "import sys\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains all functionaility in relation to building and running the RS model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_indptr(users):\n",
    "    \"\"\"\n",
    "    Creates the indptr array for the set of users.\n",
    "    \n",
    "    Input:\n",
    "        users; Pandas Series, the set of users associated to each row in the main data set.\n",
    "    Output:\n",
    "        indptr; list, the row values associated to each user.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    counter = 0\n",
    "    indptr = [0]\n",
    "    # Loop through each unique user.\n",
    "    for unique in users.unique():\n",
    "        # counter responds to the position in the array.\n",
    "        counter += len(users[users == unique])\n",
    "        indptr.append(counter)\n",
    "    \n",
    "    return(indptr)\n",
    "#indptr = calculate_indptr(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data, factors = 64, regularization = 0.0, bm25 = True, iterations = 15, alpha = 1.0):\n",
    "    \n",
    "    indptr = calculate_indptr(data['userID'])\n",
    "    user_items = csr_matrix((data['count'], data['trackID'], indptr))\n",
    "    \n",
    "    # weight the matrix, both to reduce impact of users that have played the same artist thousands of times\n",
    "    # and to reduce the weight given to popular items\n",
    "    if bm25 == True:\n",
    "        artist_user_plays = bm25_weight(user_items, K1=100, B=0.8)\n",
    "    else:\n",
    "        artist_user_plays = user_items\n",
    "\n",
    "    # get the transpose since the most of the functions in implicit expect (user, item) sparse matrices instead of (item, user)\n",
    "    # user_plays = artist_user_plays.T.tocsr()\n",
    "    user_plays = artist_user_plays.tocsr()\n",
    "\n",
    "    model = AlternatingLeastSquares(factors = factors, \n",
    "                                    regularization = regularization, \n",
    "                                    iterations = iterations)#,alpha = alpha)\n",
    "\n",
    "    model.fit(alpha * user_plays)\n",
    "    return(model, user_plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_exploratoryness(user_history): \n",
    "    \"\"\"\n",
    "    Calculates the track exploratoryness from a users history\n",
    "    \n",
    "    Input:\n",
    "        user_history: dataframe, contains all of the users history\n",
    "    Output:\n",
    "        track explotoryness, can be calucalated using exploratoryness or unique by commenting the relative lines.\n",
    "    \"\"\"\n",
    "    return(  1  - ((1/user_history['count'].sum())* np.sum(user_history['count'].sort_values(ascending = False)/range(1,len(user_history['count'])+1))))\n",
    "    #return(len(user_history['trackID'].unique()))\n",
    "    \n",
    "    \n",
    "def artist_exploratoryness(user_history):  \n",
    "    \"\"\"\n",
    "    Calculates the artists exploratoryness from a users history\n",
    "    \n",
    "    Input:\n",
    "        user_history: dataframe, contains all of the user's history\n",
    "    Output:\n",
    "        artist explotoryness, can be calucalated using exploratoryness or unique by commenting the relative files.\n",
    "    \"\"\"\n",
    "    #return(1- ((1/user_history['count'].sum()) * (np.sum(user_history.groupby('artist-MBID').sum('count')['count'].sort_values(ascending = False) / range(1, len(user_history['artist-MBID'].unique())+1)))))\n",
    "    return(len(user_history['artist-MBID'].unique()))\n",
    "\n",
    "def calculate_exploratoryness(user_track_exploration, user_artist_exploration, sample_ids, user_histories):  \n",
    "    \"\"\"\n",
    "    Iterates through each of the sample user and adds their exploratoryness to the relavent files.\n",
    "    \n",
    "    Input\n",
    "        user_track_exploration; dictionary {userID, list of exploratoryness} the track exploratoryness of each user\n",
    "        user_artist_exploration; dictionary {userID, list of exploratoryness} the artist exploratoryness of each user\n",
    "        sample_ids; list of int, the list of sample users for the test\n",
    "        user_histories; Dictionary{userid, dataframe of user history}, the user history for each user.\n",
    "    \"\"\"\n",
    "    for user_id in sample_ids:\n",
    "        history = user_histories[user_id]\n",
    "        user_track_exploration[user_id].append(track_exploratoryness(history))\n",
    "        user_artist_exploration[user_id].append(artist_exploratoryness(history))\n",
    "    return(user_track_exploration, user_artist_exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decay_predictions(model, userid, user_history, user_decay, n_decay, filter_already_liked_items):\n",
    "    \"\"\"\n",
    "    Obtains predictions when the decay model is active.\n",
    "    \n",
    "    Input \n",
    "        model; the RS model implemented\n",
    "        userid; int, the users id\n",
    "        user_history; Dataframe, the users history\n",
    "        user_decay; Dictionary{trackID,decay_value} the decay values for each of the recommended tracks for that user\n",
    "        n_decay; int, the length of decay set\n",
    "        filter_already_liked_items; bool, whether the model is set to prevent liked items appearing\n",
    "    \n",
    "    Output\n",
    "        user_decay; Dictionary{trackID,decay_value} the updated decay values for the given user\n",
    "        valid_track_ids; list of int, the tracks recommended to the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generates enough recommendations so that 10 do not have a decay set.\n",
    "    track_ids, scores = model.recommend(userid, user_history, N=len(user_decay.keys())+10, filter_already_liked_items=False)\n",
    "    \n",
    "    valid_track_ids = []\n",
    "    i = 0\n",
    "    \n",
    "    # Add new tracks to the decay\n",
    "    while len(valid_track_ids) < 10:\n",
    "        if track_ids[i] not in user_decay.keys():\n",
    "            valid_track_ids.append(track_ids[i])\n",
    "            user_decay[track_ids[i]] = n_decay\n",
    "        i+=1\n",
    "        \n",
    "    \n",
    "    return(user_decay, valid_track_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_decay(user_decay):\n",
    "    \"\"\"\n",
    "    Updates the decay by subtracting 1 from its value and removing recommendations with 0 decay.\n",
    "    \n",
    "    Input\n",
    "        user_decay; dict{track_name:decay value} each track's decay\n",
    "    Output\n",
    "        user_decay; dict{track_name:decay value} each track's updated decay\n",
    "    \"\"\"\n",
    "    # Create a list of tracks that need to be deleted so it can be performed outside the loop\n",
    "    to_delete = []\n",
    "    for track in user_decay.keys():\n",
    "        user_decay[track] -= 1\n",
    "        # Removes tracks with no decay left.\n",
    "        if user_decay[track] == 0:\n",
    "            to_delete.append(track) \n",
    "    for track in to_delete:\n",
    "        del(user_decay[track])\n",
    "    return(user_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sim_songs(user_history, n_sim_songs):\n",
    "    \"\"\"\n",
    "    increment n_sim_songs songs  to the users history.\n",
    "    \n",
    "    Input:\n",
    "        user_history; Dataframe, the users listening history\n",
    "        n_sim_songs; int, the number of songs to add to the users history.\n",
    "    \n",
    "    Output:\n",
    "        user_history; Dataframe, the users updated listening history\n",
    "    \"\"\"\n",
    "    # Take a random sample of track from the user's listening history\n",
    "    sim_listening = user_history['trackID'].sample(n_sim_songs)\n",
    "    mask = user_history['trackID'].isin(sim_listening)\n",
    "    user_history['count'][mask] += 1\n",
    "    return(user_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions(track_ids, unique_tracks, user_history, userid):\n",
    "    \"\"\"\n",
    "    Using the track Ids extract the relavent information about each recommendation and update the users history.\n",
    "    \n",
    "    \n",
    "    Inputs:\n",
    "        track_ids; list of int\n",
    "        unique_tracks; Dataframe, contains all metadata about each unique track in the total dataset.\n",
    "        user_history; Dataframe, the users listening history\n",
    "        userid; int\n",
    "    Output;\n",
    "        user_history; dataframe, the updated user history\n",
    "        prediction_data; dataframe, meta data about each prediction\n",
    "    \"\"\"\n",
    "    prediction_data = pd.DataFrame(unique_tracks.loc[track_ids])\n",
    "    prediction_data['already_liked'] = prediction_data['recordingMBID'].isin(user_history['recordingMBID'])\n",
    "\n",
    "    #Update their user history\n",
    "    for track in prediction_data.index:\n",
    "        row = prediction_data.loc[track]\n",
    "        if prediction_data.loc[track]['already_liked'] == True:\n",
    "            mask = user_history['trackID'] == track\n",
    "            user_history['count'][mask] += 1\n",
    "        else:\n",
    "            user_history.loc[user_history.shape[0]] = [row['artist-MBID'], 1, \"unkown\", row['recordingMBID'], row['trackName'], userid, track, row['artistName']]\n",
    "    #print(len(prediction_data))\n",
    "    return (user_history, prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_model(data, n_simulations, sample_ids,\n",
    "                   n_recommendations = 10,\n",
    "                   decay = False, \n",
    "                   n_decay = 5,\n",
    "                   sim_rand_listen = False,\n",
    "                   n_sim_songs = 10, \n",
    "                   filter_already_liked_items = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Simulates the multiple users using the recommendation system for a given number of iterations:\n",
    "    \n",
    "    Input:\n",
    "        data; Pandas dataframe, the whole dataset including MBID's, Names and the test data.\n",
    "        n_simulations; int, the number of sets of recommendations to generate\n",
    "        sample_ids; list of int, the user ids tested.\n",
    "        n_recommendations; int default = 10, the number of recommendations within each iteration\n",
    "        decay; Bool default = True, Whether to implement a recommendation decay\n",
    "        n_decay; Int default = 5, the length of decay if implement. (set to n_simulations for inf decay)\n",
    "        sim_rand_listen; Bool default = False, whether to add random listens to a users history\n",
    "        n_sim_songs; int default = 10, the number of random songs to add to a users history\n",
    "        filter_already_liked_items; Bool default = False, whether the recommendation system should only produce new tracks.\n",
    "    \n",
    "    Output:\n",
    "        user_track_exploration; Dictionary {userid:[exploration]}, each users list of track exploratoryness\n",
    "        user_artist_exploration; Dictionary {userid:[unique artist]}, each users number of unique artists\n",
    "        user_predictions; Dictionary {userid:[prediction]}, each users preditions\n",
    "        model; ALS Model, the modified model.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Take a copy of the data to prevent changing the test dataset.\n",
    "    test_data = data.copy()\n",
    "    # Extract the data required for the model.\n",
    "    model_data = test_data[['userID','trackID','count']]\n",
    "    \n",
    "    \n",
    "    user_track_exploration = {idd: [] for idd in sample_ids}\n",
    "    user_artist_exploration = {idd: [] for idd in sample_ids}\n",
    "    user_predictions = {idd: [] for idd in sample_ids}\n",
    "    user_prediction_decay = {idd: {} for idd in sample_ids}\n",
    "    \n",
    "    # creates the model\n",
    "    model, user_plays = create_model(model_data, bm25 = True)\n",
    "    \n",
    "    # Extracts each of the user's user histories into a dictionary\n",
    "    user_histories = {user_id : test_data[test_data['userID'] == user_id] for user_id in sample_ids}\n",
    "\n",
    "    # Obtains each of the unique tracks availble to users within the simulation.\n",
    "    unique_tracks = test_data.drop_duplicates(subset = [\"trackID\"])\n",
    "    unique_tracks = unique_tracks[['trackID','recordingMBID', 'trackName', 'artist-MBID', 'artistName']].set_index('trackID')\n",
    "    \n",
    "    \n",
    "    for n in tqdm(range(n_simulations)):\n",
    "\n",
    "        for userid in sample_ids:\n",
    "            \n",
    "            # Obtain just that user's history\n",
    "            user_history = user_histories[userid]\n",
    "            \n",
    "            if decay == True:\n",
    "                \n",
    "                user_decay, track_ids = get_decay_predictions(model, userid, user_history, user_prediction_decay[userid], n_decay, filter_already_liked_items)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                track_ids, scores = model.recommend(userid, user_history, n_recommendations, filter_already_liked_items)\n",
    "            \n",
    "            if sim_rand_listen == True:\n",
    "                user_history = add_sim_songs(user_history, n_sim_songs)\n",
    "              \n",
    "            # Obtains the predictions for that user and adds to the user's history\n",
    "            user_history, prediction_data = add_predictions(track_ids, unique_tracks, user_history, userid)\n",
    "            \n",
    "            # Updates the model\n",
    "            predictions = user_history['trackID'].values\n",
    "            indptr = [0,len(predictions)]\n",
    "\n",
    "            user_items = csr_matrix((user_history['count'].values, predictions, indptr))\n",
    "            \n",
    "            # Only updates the model for that user.\n",
    "            model.partial_fit_users([userid], user_items)\n",
    "            \n",
    "            user_predictions[userid].append(prediction_data)\n",
    "            \n",
    "            to_delete = []     \n",
    "            user_histories[userid] = user_history\n",
    "            if decay == True:\n",
    "                user_prediction_decay[userid] = update_decay(user_decay)\n",
    "                    \n",
    "        # Records the data after every 5 rounds.            \n",
    "        if n%5 == 0:\n",
    "            user_track_exploration, user_artist_exploration = calculate_exploratoryness(user_track_exploration, user_artist_exploration, sample_ids, user_histories)\n",
    "            \n",
    "\n",
    "    return(user_track_exploration, user_artist_exploration, user_predictions, model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uk_data = pd.read_pickle('../../cleaned_data/uk_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_ids = np.random.choice(uk_data['userID'].unique(),20)\n",
    "#uk_user_track_exploration, uk_user_artist_exploration, uk_user_predictions = simulate_model(uk_data, 100, sample_ids, sim_rand_listen = True, decay = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
